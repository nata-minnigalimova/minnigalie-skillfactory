{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   \n\n\n\n### И самое важное, все это вы сможете сделать самостоятельно!\n\n*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \nВы можете использовать его как основу для построения своего решения.\n\n> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \nТакже baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n\nВ контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."},{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Reviews[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки."},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data\nОбычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим количество пропусков в каждом признаке.\n\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пропуски содержат признаки Cuisine Style (23%), Price Range (35%), Number of Reviews (6%). Целевая переменная Rating пропусков не содержит."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оформим названия признаков в едином стиле для удобства дальнейшей работы.\n\ndata.columns = ['_'.join(col.split()).lower() for col in data.columns]\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выберем случайный образец данных из таблицы и посмотрим на него.\n\ndata.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак **cuisine_style** в действительности описывает не только тип кухни по страновому признаку (например, Japanese или Italian), но и типы блюд (Suschi, Sopups) или формат ресторана (Fast Food, Cafe) Возможно, это удастся использовать в дальнейшем."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Определим уникальные значения целевой переменной и ее распределение.\n\ndata.rating.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Определим вид и тип содержимого признака reviews.\n\nprint(data.reviews[2])\nprint(type(data.reviews[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Определим вид и тип содержимого признака url_ta.\n\nprint(data.url_ta[2])\nprint(type(data.url_ta[2]))\nprint(data.url_ta[5])\nprint(type(data.url_ta[5]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В этом признаке содержится указание на район расположения ресторана, возможно, это будет влиять на его рейтинг."},{"metadata":{},"cell_type":"markdown","source":"### Работа с признаками"},{"metadata":{},"cell_type":"markdown","source":"#### restaurant_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.restaurant_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что есть значительное количество повторов, то есть ID ресторанов не уникальны. Это может быть связано как с ошибками при заполнении таблицы, так и с тем, что ресторан - сетевой. Тем более, что раньше при просмотра признака Cuisine Style мы видели указания на то, что ресторан может быть сетевым (формат заведения Fast Food, Cafe)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим примеры ресторанов с одинаковым ID.\n\ndata[(data.restaurant_id == 'id_633')].sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим много совпадений в признаках ranking и price_range, однако описания кухни очень разнятся. Нельзя сказать однозначно что одинаковый ID имеют именно сетевые рестораны, но это утверждение можно оставить в качестве предположения."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим дополнительный признак Сетевой ресторан (chain_rest).\n# Значения: 1 - сетевой ресторан, 0 - несетевой ресторан.\n\nchain_list = list(data.restaurant_id.value_counts()[data.restaurant_id.value_counts() > 1].index)\ndata['chain_rest'] = data[data.restaurant_id.isin(chain_list)].restaurant_id.apply(lambda x: 1)\ndata['chain_rest'].fillna(0, inplace=True)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создан новый признак chain_rest. Проверим его уникальные значения.\n\ndata.chain_rest.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пропусков и случайных неуникальных значений в признаке нет. Большая часть ресторанов по нашим предположениям - сетевые."},{"metadata":{},"cell_type":"markdown","source":"#### city"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Посмотрим на список городов, представленный в признаке и заодно на его распределение.\n\ndata.city.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что большинство ресторанов расположены в наиболее посещаемых туристических столицах мира (что соответсвует тематике сайта, который дает советы путешественникам). При этом самые популярные города не всегда совпадают со столицами стран (Милан опережает Рим). Кроме того, есть странное название города Oportо. Википедия говорит нам, что в португальском языке есть два варианта написания названия города Порту - Oporto и Porto, повторов нет, поэтому исправлять мы его не будем."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создадим признак, указывающий на то, является ли город столицей (capital).\n\ncap_list = ['London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', 'Lisbon', 'Vienna', 'Amsterdam', 'Brussels', \n           'Stockholm', 'Budapest', 'Budapest', 'Dublin', 'Copenhagen', 'Edinburgh', 'Oslo', 'Helsinki', 'Bratislava',\n           'Luxembourg', 'Ljubljana']\ndata['capital'] = data[data.city.isin(cap_list)].city.apply(lambda x: 1)\ndata['capital'].fillna(0, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создан новый признак capital. Проверим его уникальные значения.\n\ndata.capital.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На рейтинг ресторана могут влиять экономические показатели - доходы, получаемые от туризма и внутренний валовый продукт. Первый показатель говорит нам о том, какое количество денег могут потратить на посещение ресторана туристы, второй - о том, насколько потенциально высок уровень цен в стране. Данные получены из открытых источников и приводятся по состоянию на 2019 год."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавим признак country.\n#Для этого создадим сначала справочник городов и стран.\n\ncountry_dict = {\n    'Paris': 'France',\n    'Stockholm': 'Sweden',\n    'London': 'UK',\n    'Berlin': 'Germany', \n    'Munich': 'Germany',\n    'Oporto': 'Portugal', \n    'Milan': 'Italy',\n    'Bratislava': 'Slovakia',\n    'Vienna': 'Austria', \n    'Rome': 'Italy',\n    'Barcelona': 'Spain',\n    'Madrid': 'Spain',\n    'Dublin': 'Ireland',\n    'Brussels': 'Belgium',\n    'Zurich': 'Switzerland',\n    'Warsaw': 'Poland',\n    'Budapest': 'Hungary', \n    'Copenhagen': 'Denmark',\n    'Amsterdam': 'Netherlands',\n    'Lyon': 'France',\n    'Hamburg': 'Germany', \n    'Lisbon': 'Portugal',\n    'Prague': 'Czech',\n    'Oslo': 'Norway', \n    'Helsinki': 'Finland',\n    'Edinburgh': 'UK',\n    'Geneva': 'Switzerland',\n    'Ljubljana': 'Slovenia',\n    'Athens': 'Greece',\n    'Luxembourg': 'Luxembourg',\n    'Krakow': 'Poland'       \n}\n\ndata['country'] = data.city.map(country_dict)\n\ndata.country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что подавляющее число ресторанов расположено в Великобритании, Испании, Франции."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Проверим новый признак на наличие пропусков.\n\ndata.country.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пропусков нет, значит, мы определили страну для каждого города. Страна будет маркером для распределения экономических данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавим признак tourism_income.\n#Для этого создадим сначала справочник стран и доходов от туризма (в миллионах долларов).\n\ntourism_dict = {\n    'Austria': 22979,\n    'Belgium': 13474,\n    'Czech': 7451,\n    'Denmark': 8420, \n    'Finland': 3607,\n    'France': 67370, \n    'Germany': 42977,\n    'Greece': 19029,\n    'Hungary': 6930, \n    'Ireland': 6185,\n    'Italy': 49262,\n    'Luxembourg': 4990,\n    'Netherlands': 18641,\n    'Norway': 5672,\n    'Poland': 14042,\n    'Portugal': 19621,\n    'Slovakia': 3200, \n    'Slovenia': 3194,\n    'Spain': 73765,\n    'Sweden': 14977,\n    'Switzerland': 17042, \n    'UK': 51882     \n}\n\ndata['tourism_income'] = data.country.map(tourism_dict)\n\n#Проверим новый признак на наличие пропусков.\n\ndata.tourism_income.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пропусков нет, значит, каждому городу присвоена страна. Проверим на примере правильность распределения городов по странам."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Все верно. Продолжаем создание новых признаков на основании экономических данных - ВВП."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавим признак gdp.\n#Для этого создадим сначала справочник стран и ВВП на душу населения (в долларах).\n\ngdp_dict = {\n    'Austria': 52813,\n    'Belgium': 49912,\n    'Czech': 39511,\n    'Denmark': 53449, \n    'Finland': 48098,\n    'France': 47322, \n    'Germany': 54874,\n    'Greece': 30501,\n    'Hungary': 33033, \n    'Ireland': 83001,\n    'Italy': 40923,\n    'Luxembourg': 113550,\n    'Netherlands': 58095,\n    'Norway': 76243,\n    'Poland': 33072,\n    'Portugal': 33211,\n    'Slovakia': 36878, \n    'Slovenia': 38343,\n    'Spain': 41998,\n    'Sweden': 54666,\n    'Switzerland': 65077, \n    'UK': 46870     \n}\n\ndata['gdp'] = data.country.map(gdp_dict)\n\n#Проверим новый признак на наличие пропусков.\n\ndata.gdp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно предположить, что какую-то роль в ценообразовании и рейтинге ресторана играет соотношение туристических доходов и уровня жизни в стране. Создадим еще один новый признак - отношение доходов от туризма к ВВП на душу населения. Назовем его tour_inc_gdp."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['tour_inc_gdp'] = (data.tourism_income / data.gdp).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Посмотрим на распределение нового признака в датасете.\n\nplt.figure(figsize=(10,4))\ndata.tour_inc_gdp.value_counts(ascending=False).plot(kind='bar')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что большинство ресторанов находятся в странах, где доходы от туризма первышают ВВП на душу населения, то есть в туристических центрах.\n\nВизуализируем отношение признака tour_inc_gdp и рейтинга ресторанов."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['tour_inc_gdp'][data['rating'] > 3].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что высокий рейтинг (более 3 пунктов) имеют рестораны с высоким доходом от туризма."},{"metadata":{},"cell_type":"markdown","source":"#### cuisine_style"},{"metadata":{},"cell_type":"markdown","source":"Ранее мы видели, что в признаке cuisine_style имеется 23% пропусков. К сожалению, прямой корреляции между городом, страной и типом кухни нет (Будапешт - венгерская), поэтому имеющиеся пробелы мы заполним строковым выражением. Перед этим создадим колонку, в которой отразим наличие пропусков в признаке."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Отражаем наличие пропусков в исходных данных и заполняем их в текущем признаке.\n\ndata['cuisine_style_NAN'] = data['cuisine_style'].isna().astype('uint8')\ndata['cuisine_style'].fillna(\"['Other']\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Количество кухонь может влиять на рейтинг, поэтому добавляем этот признак. Там, где кухня не определена (замена пропусков), количество будем считать равным 1 (в любом ресторане представлена по крайней мере 1 кухня, никакие другие признаки не дают нам возможность сделать заполнение более точным)."},{"metadata":{"trusted":true},"cell_type":"code","source":"type(data['cuisine_style'][2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Преобразуем строковые данные с названиями кухонь в список\ndata['cuisine_style_list'] = data['cuisine_style'].str.findall(r\"'(\\b.*?\\b)'\")\n\n#Заполним пропуски 0\ndata['cuisine_style_list'] = data['cuisine_style_list'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(data['cuisine_style_list'][2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cuisine_style_list'][2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создадим новый признак - количество кухонь в ресторане (cuisine_count).\ndata['cuisine_count'] = data['cuisine_style_list'].apply(lambda x: 1 if x == 0 else len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Просматриваем уникальные значения и распределения нового признака.\n\ndata.cuisine_count.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Учитывая то, что в исходном датасете в признаке cuisine_style пропуски заменяли более 23%, которые мы затем заменили на 1, понятно, почему в большинстве ресторанов представлен один вид кухни.\nПосмотрим, какие виды кухонь встречаются реже всего, чтобы определить редкие и создать признак для количества редких кухонь в ресторане."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,6))\ndata.explode('cuisine_style_list')['cuisine_style_list'].value_counts(ascending=False).plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Чтобы правильно определить, какие кухни считать редкими, выясним медиану частотности разных видов.\nprint((data.explode('cuisine_style_list')['cuisine_style_list'].value_counts(ascending=False)).median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rare_list = data.explode('cuisine_style_list')['cuisine_style_list'].value_counts()[\n    data.explode('cuisine_style_list')['cuisine_style_list'].value_counts() < 200].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(rare_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.explode('cuisine_style_list')['cuisine_style_list'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Также составим список самых популярных кухонь, которые есть почти в каждом ресторане."},{"metadata":{"trusted":true},"cell_type":"code","source":"popular_list = data.explode('cuisine_style_list')['cuisine_style_list'].value_counts()[\n    data.explode('cuisine_style_list')['cuisine_style_list'].value_counts() > 5900].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popular_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### price_range"},{"metadata":{"trusted":true},"cell_type":"code","source":"# уникальные значения признака price_range\ndata['price_range'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['price_range'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Замена строковых значений признака price_range\n\ndata['price_range'] = data['price_range'].fillna(0)\n\nprice_dict = {'$':1, '$$ - $$$':2, '$$$$':3}\ndata['price_range'] = data['price_range'].replace(to_replace=price_dict)\ndata['price_range'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Первая приблизительная замена выполнена. Теперь заполним пропуски в price_range более точно, для этого выясним среднее значение этого признака по городам."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 Получаем датафрейм, в котором сгруппированы только города и рейтинг цен\nprice_city =  data[['city','price_range']]\n\n# 2 Удаляем пропущенные значения из датафрейма\nprice_city = price_city.loc[price_city.ne(0).all(axis=1)]\n\n# 3 Получаем среднее значение по городам, учитывающее ненулевой рейтинг\n\nprice_city = price_city.groupby(['city'])[['price_range']].mean().round(2)\n\n# 4 Получаем словарь со средними значениями\n\nprice_range_dict = price_city['price_range'].to_dict()\nprice_range_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Заменяем пропуски средним значением по городам\nx = data['city'].where(data['price_range']==0).replace(to_replace=price_range_dict)\ndata['price_range'].where(data['price_range']!=0, other=x, inplace=True)\ndata['price_range'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### number_of_revievs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Смотрим, есть ли варианты, где в числе ревю ничего не стоит, а на самом деле ревю и даты есть\n\ndata['number_of_reviews'] = data['number_of_reviews'].fillna(0)\ndata[data['number_of_reviews'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что есть ситуации, когда ревю якобы нет, но на самом деле они есть, об этом нам говорит вывод по группировке. Создаем переменную, в которую загружаем строку, обозначающую, что ревю нет."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Словарь со значением среднего количества ревю по городам\n\n# 1 Получаем датафрейм, в котором сгруппированы только города и рейтинг цен\nnumber_reviews = data[['city','number_of_reviews']]\n\n# 2 Удаляем пропущенные значения из датафрейма\nnumber_reviews = number_reviews.dropna(axis = 0)\n\n# 3 Получаем среднее значение по городам, учитывающее ненулевое количество ревю\n\nnumber_reviews = number_reviews.groupby(['city'])[['number_of_reviews']].mean().round(0)\n\n# 4 Получаем словарь со средними значениями\n\nnumber_reviews_dict = number_reviews['number_of_reviews'].to_dict()\nnumber_reviews_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Переменная со строковым выражением, обозначающим фактическое отсутствие ревю\nno_rew = data.iloc[7][6]\nno_rew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавляем признак is_review\ndata['is_review']=0\ndata['is_review'].where(data['reviews']==no_rew,other=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Заполняем пропуски в количестве ревю средним количеством ревю по городам\n\ny = data[data['number_of_reviews'] == 0]['city'].where(data['is_review']==1).replace(to_replace=number_reviews_dict)\ndata['number_of_reviews']=data['number_of_reviews'].where(data['number_of_reviews']!=0, other=y)\ndata['number_of_reviews']=data['number_of_reviews'].fillna(0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Посмотрим на содержание ячейки с этим признаком.\n\nprint(data.iloc[1][6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(data.iloc[1][6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что в ячейке есть дата первого и последнего отзыва. Разницу в днях можно выделить как отдельный признак."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создадим сначала колонки с первой и последней датой отзывов.\n\nimport numpy as np\nimport re\nimport datetime as dt\ndef reviews_date(rew, count):\n    date = re.findall(r'\\d\\d?/\\d\\d?/\\d+', str(rew))\n    if len(date) == 0:\n        return np.nan\n    if count == 1:\n        return pd.to_datetime(date[0])\n    elif len(date) == 2:\n        return pd.to_datetime(date[1])\n    else:\n        return np.nan\n\ndata['reviews_first'] = data['reviews'].apply(lambda x: reviews_date(x, 1))\ndata['reviews_second'] = data['reviews'].apply(lambda x: reviews_date(x, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviews_first'] = data['reviews_first'].fillna(data['reviews_first'].min())\ndata['reviews_second'] = data['reviews_second'].fillna(data['reviews_second'].max())\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Найдем разницу между датами\n\ndata['time_delta'] = (data['reviews_second'] - data['reviews_first']).dt.days\ndata['time_delta'] = data['time_delta'].apply(lambda x: x*-1 if x < 0 else x)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Посмотрим, есть ли взаимосвязь между количеством ревю (отзывов) и частотой, с которой их оставляют."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['number_of_reviews','time_delta']].sample(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Видим, что довольно часто видна обратная взаимосвязь - чем больше отзывов, тем чаще их оставляют. Отразим это в новом признаке - коэффициент частотности (frequency)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['frequency'] = (data['number_of_reviews']/data['time_delta']).round(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### url_ta"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Посмотрим на содержимое ячеек."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.iloc[3][7])\nprint(data.iloc[16][7])\nprint(data.iloc[2][7])\nprint(data.iloc[22][7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Как мы можем видеть, иногда в описании ресторана есть указание на район, в котором располагается ресторан. Расположение также может влиять на рейтинг, однако указание района есть не во всех ячейках и нет регулярного паттерна, который помог бы его обнаружить (всегда на одном и том же месте, отделяется определенным знаком и т.д.) Поэтому от этого признака я предлагаю избавиться."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['url_ta'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### id_ta"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['id_ta'] = data['id_ta'].apply(lambda x: int(x[1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data, columns=['city'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.join(pd.get_dummies(data['cuisine_style_list'].apply(pd.Series).stack()).sum(level=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы видим, что появилось множество признаков с названиями редких кухонь и самых популярных кухонь, которые не могут иметь большого внимания на целевую переменную (популярные кухни есть везде, редкие кухни относятся к небольшому количеству ресторанов). Поэтому возьмем названия редких и популярных кухонь из словарей, которые мы создали при работе cuisine_style и удалим эти признаки по списку."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(rare_list, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(popular_list, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Удаление нечисловых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Смотрим, какие признаки включают в себя объектные данные\n\ndata.select_dtypes(include = ['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создадим список признаков с объектными данными для удаления\n\ndrop_list = ['restaurant_id', 'cuisine_style', 'reviews', 'country',\n       'cuisine_style_list']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Удаляем объектные признаки\n\ndata = data.drop(drop_list, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем даты, поскольку из этих данных мы уже получили частоту отзывов.\n\ndata = data.drop(['reviews_first'], axis = 1)\ndata = data.drop(['reviews_second'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Распределение целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndata['rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,11)\nsns.heatmap(data.corr(), cmap='vlag')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Корреляция с целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr().rating.sort_values(ascending=False).to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df_output.drop(['Restaurant_id','ID_TA',], axis = 1, inplace=True)\n    \n    \n    # ################### 2. NAN ############################################################## \n    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n    df_output['Number of Reviews'].fillna(0, inplace=True)\n    # тут ваш код по обработке NAN\n    # ....\n    \n    \n    # ################### 3. Encoding ############################################################## \n    # для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n    df_output = pd.get_dummies(df_output, columns=[ 'City',], dummy_na=True)\n    # тут ваш код не Encoding фитчей\n    # ....\n    \n    \n    # ################### 4. Feature Engineering ####################################################\n    # тут ваш код не генерацию новых фитчей\n    # ....\n    \n    \n    # ################### 5. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    return df_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). "},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What's next?\nИли что делать, чтоб улучшить результат:\n* Обработать оставшиеся признаки в понятный для машины формат\n* Посмотреть, что еще можно извлечь из признаков\n* Сгенерировать новые признаки\n* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n* Подобрать состав признаков\n\nВ общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}